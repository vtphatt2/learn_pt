{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias \n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "idx = torch.randperm(X.size(0))\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "\n",
    "We'll use `nn.Linear(in_features, out_features)` to do it for us.\n",
    "\n",
    "Where `in_features` is the number of dimensions your input data has and `out_features` is the number of dimensions you'd like it to be output to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[-0.6095]])),\n",
       "             ('linear_layer.bias', tensor([-0.9899]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "    \n",
    "model = LinearRegressionModel()\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model device\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train Loss: 3.7767555713653564 - Test Loss: 4.0589776039123535\n",
      "Epoch 100 - Train Loss: 0.04283986613154411 - Test Loss: 0.055265165865421295\n",
      "Epoch 200 - Train Loss: 0.013779409229755402 - Test Loss: 0.013494606129825115\n",
      "Epoch 300 - Train Loss: 0.010380047373473644 - Test Loss: 0.009498926810920238\n",
      "Epoch 400 - Train Loss: 0.00791314709931612 - Test Loss: 0.007194265723228455\n",
      "Epoch 500 - Train Loss: 0.006033158861100674 - Test Loss: 0.0054817101918160915\n",
      "Epoch 600 - Train Loss: 0.004599820356816053 - Test Loss: 0.004179146606475115\n",
      "Epoch 700 - Train Loss: 0.0035070031881332397 - Test Loss: 0.0031862519681453705\n",
      "Epoch 800 - Train Loss: 0.002673821523785591 - Test Loss: 0.002429274609312415\n",
      "Epoch 900 - Train Loss: 0.0020385857205837965 - Test Loss: 0.0018521398305892944\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred_test = model(X_test)\n",
    "        loss_test = loss_fn(y_pred_test, y_test)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch} - Train Loss: {loss.item()} - Test Loss: {loss_test.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('linear_layer.weight', tensor([[0.5648]], device='mps:0')),\n",
      "             ('linear_layer.bias', tensor([0.3682], device='mps:0'))])\n",
      "\n",
      "And the original values for weights and bias are:\n",
      "weights: 0.7, bias: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VoThinhPhat/Library/Python/3.9/lib/python/site-packages/torch/_tensor_str.py:138: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:335.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "# Find our model's learned parameters\n",
    "from pprint import pprint # pprint = pretty print, see: https://docs.python.org/3/library/pprint.html \n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "pprint(model.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weight}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8879],\n",
       "        [0.6280],\n",
       "        [0.6167],\n",
       "        [0.7636],\n",
       "        [0.4473],\n",
       "        [0.6393],\n",
       "        [0.9217],\n",
       "        [0.6958],\n",
       "        [0.8201],\n",
       "        [0.4699]], device='mps:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_pred = model(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Many data science libraries such as pandas, matplotlib and NumPy aren't capable of using data that is stored on GPU. So you might run into some issues when trying to use a function from one of these libraries with tensor data not stored on the CPU. To fix this, you can call `.cpu()` on your target tensor to return a copy of your target tensor on the CPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
